import os
import json
import torch
from accelerate import Accelerator
from PIL import Image
import matplotlib.pyplot as plt
from torch.utils.data import Dataset, DataLoader
from tqdm import tqdm
from torchvision import transforms
import random
import numpy as np

from diffusers import (
    UNet2DConditionModel,
    AutoencoderKL,
    DDPMScheduler,
    StableDiffusionPipeline,
)
from diffusers.training_utils import cast_training_params
from diffusers.optimization import get_scheduler
from diffusers.utils import convert_state_dict_to_diffusers
from transformers import CLIPTextModel, CLIPTokenizer
from peft import LoraConfig, get_peft_model_state_dict

DATA_DIR = "/content/drive/MyDrive/VisDrone2019-YOLO/VisDrone2019-YOLO-renamed/"
PROMPT_FILE = "prompt.jsonl"
OUTPUT_DIR = "/content/drive/MyDrive/VisDrone2019-YOLO/trained_lora_controlnet/"
CHECKPOINT_DIR = "/content/drive/MyDrive/VisDrone2019-YOLO/checkpoints"
PRETRAINED_MODEL_PATH = "stable-diffusion-v1-5/stable-diffusion-v1-5"

os.makedirs(OUTPUT_DIR, exist_ok=True)
os.makedirs(CHECKPOINT_DIR, exist_ok=True)

# ğŸ›¡ï¸ å®‰å…¨æ¸è¿›ä¿®å¤å‚æ•° - å¹³è¡¡æ•ˆæœä¸ç¨³å®šæ€§
BATCH_SIZE = 2
EPOCHS = 15
LR = 3e-4  # ğŸ›¡ï¸ é€‚åº¦æå‡: 2e-4 â†’ 3e-4 (50%æå‡ï¼Œæ›´å®‰å…¨)
GRADIENT_ACCUMULATION_STEPS = 3  # ğŸ›¡ï¸ é€‚åº¦å‡å°‘: 4 â†’ 3
SCALE_LR = False  # ç¦ç”¨å­¦ä¹ ç‡ç¼©æ”¾
MAX_TOKEN_LENGTH = 77
IMAGE_SIZE = 512
CACHE_LATENTS = True
WARMUP_STEPS = 100  # ğŸ›¡ï¸ ä¿æŒé€‚åº¦warmup
MIN_SNR_GAMMA = 2.0  # ğŸ›¡ï¸ é€‚åº¦å¯ç”¨Min-SNR (åŸæ¥5.0å¤ªå¤§ï¼Œç°åœ¨2.0)
NOISE_OFFSET = 0.05
MAX_GRAD_NORM = 1.5  # ğŸ›¡ï¸ é€‚åº¦æ”¾å®½: 1.0 â†’ 1.5
SAVE_STEPS = 500
VALIDATION_STEPS = 200

epoch_losses = []
step_losses = []
weight_dtype = torch.float16 if torch.cuda.is_available() else torch.float32


def set_seed(seed=42):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)


set_seed(42)

# åˆå§‹åŒ–Accelerator
accelerator = Accelerator(
    gradient_accumulation_steps=GRADIENT_ACCUMULATION_STEPS,
    mixed_precision="fp16" if torch.cuda.is_available() else "no",
    log_with="tensorboard",
    project_dir=os.path.join(OUTPUT_DIR, "logs")
)

print(f"ğŸ›¡ï¸ å®‰å…¨æ¸è¿›ä¿®å¤è®­ç»ƒé…ç½®:")
print(f"ä½¿ç”¨è®¾å¤‡: {accelerator.device}")
print(f"æ··åˆç²¾åº¦: {accelerator.mixed_precision}")

# åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
noise_scheduler = DDPMScheduler.from_pretrained(PRETRAINED_MODEL_PATH, subfolder="scheduler")
tokenizer = CLIPTokenizer.from_pretrained(PRETRAINED_MODEL_PATH, subfolder="tokenizer")
text_encoder = CLIPTextModel.from_pretrained(PRETRAINED_MODEL_PATH, subfolder="text_encoder")
vae = AutoencoderKL.from_pretrained(PRETRAINED_MODEL_PATH, subfolder="vae")
unet = UNet2DConditionModel.from_pretrained(PRETRAINED_MODEL_PATH, subfolder="unet")

# å†»ç»“é¢„è®­ç»ƒå‚æ•°
unet.requires_grad_(False)
vae.requires_grad_(False)
text_encoder.requires_grad_(False)

# ğŸ›¡ï¸ æ¸è¿›çš„LoRAé…ç½® - å¹³è¡¡è¡¨è¾¾èƒ½åŠ›ä¸ç¨³å®šæ€§
unet_lora_config = LoraConfig(
    r=48,  # ğŸ›¡ï¸ é€‚åº¦å¢åŠ : 32 â†’ 48 (50%æå‡)
    lora_alpha=48,  # alpha = rank
    init_lora_weights="gaussian",
    target_modules=["to_k", "to_q", "to_v", "to_out.0"],
    lora_dropout=0.05,  # ğŸ›¡ï¸ è½»å¾®dropoutä¿æŠ¤
)

# ç§»åŠ¨æ¨¡å‹åˆ°è®¾å¤‡
text_encoder = text_encoder.to(accelerator.device, dtype=weight_dtype)
vae = vae.to(accelerator.device, dtype=weight_dtype)
unet = unet.to(accelerator.device, dtype=weight_dtype)

# æ·»åŠ LoRAé€‚é…å™¨
unet.add_adapter(unet_lora_config)

# è®¾ç½®è®­ç»ƒå‚æ•°
cast_training_params(unet, dtype=torch.float32)

# è·å–LoRAå¯è®­ç»ƒå‚æ•°
lora_layers = list(filter(lambda p: p.requires_grad, unet.parameters()))
print(f"å¯è®­ç»ƒå‚æ•°æ•°é‡ï¼ˆLoRAï¼‰ï¼š{len(lora_layers)}")
print(f"å¯è®­ç»ƒå‚æ•°æ€»é‡ï¼š{sum(p.numel() for p in lora_layers)}")

# éªŒè¯LoRAå‚æ•°
print("\nğŸ” éªŒè¯LoRAå‚æ•°:")
lora_param_count = 0
for name, param in unet.named_parameters():
    if param.requires_grad and 'lora' in name:
        print(f"  {name}: shape={param.shape}, requires_grad={param.requires_grad}")
        lora_param_count += 1
        if lora_param_count >= 3:  # åªæ˜¾ç¤ºå‰3ä¸ª
            break

# å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹
if hasattr(unet, "enable_gradient_checkpointing"):
    unet.enable_gradient_checkpointing()

# ğŸ›¡ï¸ æ›´ä¿å®ˆçš„ä¼˜åŒ–å™¨
optimizer = torch.optim.AdamW(
    lora_layers,
    lr=LR,
    betas=(0.9, 0.999),
    weight_decay=8e-3,  # ğŸ›¡ï¸ é€‚åº¦æƒé‡è¡°å‡: 1e-2 â†’ 8e-3
    eps=1e-8,
)

# ğŸ¯ ä¸“æ³¨è®¡æ•°ä»»åŠ¡ - å®Œå…¨ä¸ç”¨æ•°æ®å¢å¼º
transform = transforms.Compose([
    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),
    transforms.ToTensor(),
    transforms.Normalize([0.5] * 3, [0.5] * 3),
])


class VisDroneControlNetDataset(torch.utils.data.Dataset):
    def __init__(self, root_dir, prompt_file, tokenizer, vae=None, max_length=MAX_TOKEN_LENGTH, transform=None):
        self.root_dir = root_dir
        self.tokenizer = tokenizer
        self.max_length = max_length
        self.transform = transform
        self.vae = vae
        self.cache_latents = CACHE_LATENTS and vae is not None

        prompt_path = os.path.join(root_dir, prompt_file)
        if not os.path.exists(prompt_path):
            raise FileNotFoundError(f"Prompt file not found: {prompt_path}")

        with open(prompt_path, "r") as f:
            self.entries = [json.loads(line) for line in f]

        print(f"åŠ è½½äº† {len(self.entries)} ä¸ªè®­ç»ƒæ ·æœ¬")

        if self.cache_latents:
            print("é¢„ç¼“å­˜latentsä¸­...")
            self._cache_latents()

    def _cache_latents(self):
        """é¢„ç¼“å­˜æ‰€æœ‰å›¾ç‰‡çš„latents"""
        self.cached_latents = []
        cache_dir = os.path.join(self.root_dir, "cached_latents")
        os.makedirs(cache_dir, exist_ok=True)

        batch_size = 4

        for start_idx in tqdm(range(0, len(self.entries), batch_size), desc="ç¼“å­˜latents"):
            batch_indices = range(start_idx, min(start_idx + batch_size, len(self.entries)))

            for idx in batch_indices:
                item = self.entries[idx]
                cache_file = os.path.join(cache_dir, f"latent_{idx}.pt")

                if os.path.exists(cache_file):
                    try:
                        latent = torch.load(cache_file, map_location="cpu")
                        self.cached_latents.append(latent)
                    except:
                        self.cached_latents.append(None)
                else:
                    try:
                        image_path = os.path.join(self.root_dir, item["image"])

                        if not os.path.exists(image_path):
                            self.cached_latents.append(None)
                            continue

                        image = Image.open(image_path).convert("RGB")

                        # ç¼“å­˜æ—¶ä½¿ç”¨ç®€å•transform
                        cache_transform = transforms.Compose([
                            transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),
                            transforms.ToTensor(),
                            transforms.Normalize([0.5] * 3, [0.5] * 3),
                        ])

                        image = cache_transform(image)

                        with torch.no_grad():
                            image_tensor = image.unsqueeze(0).to(self.vae.device, dtype=self.vae.dtype)
                            latent = self.vae.encode(image_tensor).latent_dist.sample()
                            latent = latent * self.vae.config.scaling_factor
                            latent = latent.squeeze(0).cpu()

                            del image_tensor
                            torch.cuda.empty_cache()

                        torch.save(latent, cache_file)
                        self.cached_latents.append(latent)

                    except Exception as e:
                        print(f"âš ï¸ ç¼“å­˜ç¬¬{idx}ä¸ªæ ·æœ¬å¤±è´¥: {e}")
                        self.cached_latents.append(None)

            if start_idx % (batch_size * 4) == 0:
                torch.cuda.empty_cache()

    def __len__(self):
        return len(self.entries)

    def __getitem__(self, idx):
        item = self.entries[idx]

        if self.cache_latents:
            latent = self.cached_latents[idx]
            image = None
        else:
            image_path = os.path.join(self.root_dir, item["image"])

            if not os.path.exists(image_path):
                raise FileNotFoundError(f"Image not found: {image_path}")

            image = Image.open(image_path).convert("RGB")
            if self.transform:
                image = self.transform(image)
            latent = None

        tokenized = self.tokenizer(
            item["prompt"],
            padding="max_length",
            truncation=True,
            max_length=self.max_length,
            return_tensors="pt",
        )

        result = {
            "input_ids": tokenized.input_ids[0],
            "attention_mask": tokenized.attention_mask[0],
        }

        if self.cache_latents:
            result["latents"] = latent
        else:
            result["image"] = image

        return result


# åˆ›å»ºæ•°æ®é›†å’Œæ•°æ®åŠ è½½å™¨
dataset = VisDroneControlNetDataset(
    DATA_DIR,
    PROMPT_FILE,
    tokenizer,
    vae=vae if CACHE_LATENTS else None,
    transform=transform
)


def collate_fn(examples):
    input_ids = torch.stack([ex["input_ids"] for ex in examples])
    attention_mask = torch.stack([ex["attention_mask"] for ex in examples])

    result = {
        "input_ids": input_ids,
        "attention_mask": attention_mask,
    }

    if CACHE_LATENTS:
        latents = torch.stack([ex["latents"] for ex in examples])
        result["latents"] = latents
    else:
        pixel_values = torch.stack([ex["image"] for ex in examples])
        result["pixel_values"] = pixel_values

    return result


dataloader = DataLoader(
    dataset,
    batch_size=BATCH_SIZE,
    shuffle=True,
    collate_fn=collate_fn,
    num_workers=2,
    pin_memory=True,
    prefetch_factor=2,
)

# å­¦ä¹ ç‡è°ƒåº¦å™¨
num_update_steps_per_epoch = len(dataloader) // GRADIENT_ACCUMULATION_STEPS
max_train_steps = EPOCHS * num_update_steps_per_epoch

print(f"æ¯epochæ›´æ–°æ­¥æ•°: {num_update_steps_per_epoch}")
print(f"æ€»è®­ç»ƒæ­¥æ•°: {max_train_steps}")

# ğŸ›¡ï¸ å¸¦é‡å¯çš„cosineè°ƒåº¦å™¨ - æ›´å¹³æ»‘
lr_scheduler = get_scheduler(
    "cosine_with_restarts",
    optimizer=optimizer,
    num_warmup_steps=WARMUP_STEPS,
    num_training_steps=max_train_steps,
    num_cycles=2,  # é€‚åº¦é‡å¯
)


def compute_snr(timesteps, noise_scheduler):
    """è®¡ç®—ä¿¡å™ªæ¯”ç”¨äºMin-SNRæŸå¤±"""
    alphas_cumprod = noise_scheduler.alphas_cumprod
    sqrt_alphas_cumprod = alphas_cumprod ** 0.5
    sqrt_one_minus_alphas_cumprod = (1.0 - alphas_cumprod) ** 0.5

    sqrt_alphas_cumprod = sqrt_alphas_cumprod[timesteps].float()
    while len(sqrt_alphas_cumprod.shape) < len(timesteps.shape):
        sqrt_alphas_cumprod = sqrt_alphas_cumprod[..., None]

    sqrt_one_minus_alphas_cumprod = sqrt_one_minus_alphas_cumprod[timesteps].float()
    while len(sqrt_one_minus_alphas_cumprod.shape) < len(timesteps.shape):
        sqrt_one_minus_alphas_cumprod = sqrt_one_minus_alphas_cumprod[..., None]

    snr = (sqrt_alphas_cumprod / sqrt_one_minus_alphas_cumprod) ** 2
    return snr


def compute_loss_with_protection(model_pred, target, timesteps, noise_scheduler):
    """ğŸ›¡ï¸ å¸¦ä¿æŠ¤çš„æŸå¤±è®¡ç®—"""

    # åŸºç¡€MSEæŸå¤±
    base_loss = torch.nn.functional.mse_loss(model_pred.float(), target.float(), reduction="none")

    if MIN_SNR_GAMMA > 0:
        # è®¡ç®—SNRæƒé‡
        snr = compute_snr(timesteps, noise_scheduler)

        # ğŸ›¡ï¸ é™åˆ¶SNRæƒé‡èŒƒå›´ï¼Œé¿å…æç«¯å€¼
        mse_loss_weights = torch.clamp(
            torch.stack([snr, MIN_SNR_GAMMA * torch.ones_like(timesteps)], dim=1).min(dim=1)[0] / snr,
            min=0.1,  # æœ€å°æƒé‡
            max=2.0  # æœ€å¤§æƒé‡
        )

        # ç¡®ä¿æƒé‡ç»´åº¦åŒ¹é…
        while len(mse_loss_weights.shape) < len(base_loss.shape):
            mse_loss_weights = mse_loss_weights.unsqueeze(-1)

        # åº”ç”¨æƒé‡
        weighted_loss = base_loss.mean(dim=list(range(1, len(base_loss.shape)))) * mse_loss_weights
        loss = weighted_loss.mean()
    else:
        loss = base_loss.mean()

    # ğŸ›¡ï¸ å¼‚å¸¸æ£€æµ‹
    if torch.isnan(loss) or torch.isinf(loss):
        print("ğŸš¨ æ£€æµ‹åˆ°å¼‚å¸¸lossï¼Œä½¿ç”¨ç®€å•MSE")
        loss = torch.nn.functional.mse_loss(model_pred.float(), target.float(), reduction="mean")

    return loss


def safe_gradient_check(unet, step, loss_value):
    """ğŸ›¡ï¸ å®‰å…¨çš„æ¢¯åº¦æ£€æŸ¥"""
    total_grad_norm = 0
    param_count = 0
    max_grad = 0
    lora_grad_count = 0

    for name, param in unet.named_parameters():
        if param.requires_grad and param.grad is not None:
            grad_norm = param.grad.data.norm(2).item()
            total_grad_norm += grad_norm ** 2
            param_count += 1
            max_grad = max(max_grad, grad_norm)

            if 'lora' in name:
                lora_grad_count += 1

    total_grad_norm = total_grad_norm ** 0.5

    # ğŸš¨ å®‰å…¨æ£€æŸ¥
    if total_grad_norm > 50:
        print(f"ğŸš¨ Step {step}: æ¢¯åº¦èŒƒæ•°è¿‡å¤§ {total_grad_norm:.2f}ï¼Œå»ºè®®é™ä½å­¦ä¹ ç‡")
        return "high_risk"
    elif total_grad_norm > 10:
        print(f"âš ï¸ Step {step}: æ¢¯åº¦èŒƒæ•°è¾ƒé«˜ {total_grad_norm:.2f}ï¼Œéœ€è¦è§‚å¯Ÿ")
        return "medium_risk"
    elif total_grad_norm < 1e-5:
        print(f"ğŸ“‰ Step {step}: æ¢¯åº¦èŒƒæ•°è¿‡å° {total_grad_norm:.6f}ï¼Œå¯èƒ½éœ€è¦æé«˜å­¦ä¹ ç‡")
        return "too_small"
    else:
        if step % 100 == 0:  # å‡å°‘è¾“å‡ºé¢‘ç‡
            print(f"âœ… Step {step}: æ¢¯åº¦å¥åº· {total_grad_norm:.4f}, LoRAå‚æ•°:{lora_grad_count}")
        return "healthy"


def unwrap_model(model):
    model = accelerator.unwrap_model(model)
    return model


def save_lora_checkpoint(step, unet, optimizer, lr_scheduler, loss):
    """ä¿å­˜æ£€æŸ¥ç‚¹"""
    checkpoint_path = os.path.join(CHECKPOINT_DIR, f"checkpoint-{step}")
    accelerator.save_state(checkpoint_path)

    lora_path = os.path.join(CHECKPOINT_DIR, f"lora_step_{step}")
    os.makedirs(lora_path, exist_ok=True)

    unwrapped_unet = unwrap_model(unet)
    unet_lora_state_dict = convert_state_dict_to_diffusers(get_peft_model_state_dict(unwrapped_unet))

    StableDiffusionPipeline.save_lora_weights(
        save_directory=lora_path,
        unet_lora_layers=unet_lora_state_dict,
        safe_serialization=False,
    )

    print(f"æ£€æŸ¥ç‚¹ä¿å­˜åˆ°: {checkpoint_path}")
    print(f"LoRAæƒé‡ä¿å­˜åˆ°: {lora_path}")


def load_lora_checkpoint():
    """åŠ è½½æœ€æ–°çš„æ£€æŸ¥ç‚¹"""
    start_epoch = 1
    start_step = 0

    checkpoints = []
    if os.path.exists(CHECKPOINT_DIR):
        for item in os.listdir(CHECKPOINT_DIR):
            if item.startswith("checkpoint-"):
                step_num = int(item.split("-")[1])
                checkpoints.append((step_num, item))

    if checkpoints:
        checkpoints.sort(reverse=True)
        latest_checkpoint = checkpoints[0][1]
        checkpoint_path = os.path.join(CHECKPOINT_DIR, latest_checkpoint)

        print(f"å‘ç°æœ€æ–°æ£€æŸ¥ç‚¹: {latest_checkpoint}")

        try:
            accelerator.load_state(checkpoint_path)
            step_num = checkpoints[0][0]
            start_epoch = (step_num // num_update_steps_per_epoch) + 1
            start_step = step_num
            print(f"æˆåŠŸåŠ è½½æ£€æŸ¥ç‚¹ï¼Œå°†ä» epoch {start_epoch}, step {start_step} å¼€å§‹è®­ç»ƒ")

        except Exception as e:
            print(f"åŠ è½½æ£€æŸ¥ç‚¹å¤±è´¥: {e}")
            start_epoch = 1
            start_step = 0

    return start_epoch, start_step


# å°è¯•åŠ è½½æ£€æŸ¥ç‚¹
start_epoch, global_step = load_lora_checkpoint()

# å‡†å¤‡è®­ç»ƒ
unet, optimizer, dataloader, lr_scheduler = accelerator.prepare(
    unet, optimizer, dataloader, lr_scheduler
)

print(f"ğŸ›¡ï¸ å®‰å…¨æ¸è¿›ä¿®å¤é…ç½®æ€»ç»“:")
print(f"   - å­¦ä¹ ç‡é€‚åº¦æå‡: {LR} (åŸæ¥2e-4, +50%)")
print(f"   - LoRA ranké€‚åº¦å¢åŠ : {unet_lora_config.r} (åŸæ¥32, +50%)")
print(f"   - æ¢¯åº¦ç´¯ç§¯é€‚åº¦å‡å°‘: {GRADIENT_ACCUMULATION_STEPS} (åŸæ¥4)")
print(f"   - é€‚åº¦Min-SNR: gamma={MIN_SNR_GAMMA} (å¸¦ä¿æŠ¤)")
print(f"   - cosineé‡å¯è°ƒåº¦å™¨")
print(f"   - è½»å¾®dropout: {unet_lora_config.lora_dropout}")
print(f"   - é€‚åº¦æ¢¯åº¦è£å‰ª: {MAX_GRAD_NORM}")

# ğŸ›¡ï¸ å®‰å…¨æ¸è¿›è®­ç»ƒå¾ªç¯
best_loss = float('inf')
loss_history = []
grad_norm_history = []
lr_adjustment_history = []

for epoch in range(start_epoch, EPOCHS + 1):
    unet.train()
    total_loss = 0.0
    epoch_step_losses = []

    progress_bar = tqdm(dataloader, desc=f"ğŸ›¡ï¸ Safe Epoch {epoch}/{EPOCHS}")

    for step, batch in enumerate(progress_bar):
        with accelerator.accumulate(unet):
            input_ids = batch["input_ids"].to(accelerator.device)
            attention_mask = batch["attention_mask"].to(accelerator.device)

            with torch.no_grad():
                encoder_hidden_states = text_encoder(
                    input_ids=input_ids,
                    attention_mask=attention_mask
                )[0]

            if CACHE_LATENTS:
                latents = batch["latents"].to(accelerator.device, dtype=weight_dtype)
            else:
                pixel_values = batch["pixel_values"].to(accelerator.device, dtype=weight_dtype)
                with torch.no_grad():
                    latents = vae.encode(pixel_values).latent_dist.sample()
                    latents = latents * vae.config.scaling_factor

            # ğŸ² ç®€åŒ–çš„å™ªå£°ç”Ÿæˆ
            noise = torch.randn_like(latents, device=accelerator.device, dtype=weight_dtype)
            if NOISE_OFFSET > 0:
                noise += NOISE_OFFSET * torch.randn(latents.shape[0], latents.shape[1], 1, 1,
                                                    device=accelerator.device, dtype=weight_dtype)

            timesteps = torch.randint(
                0, noise_scheduler.config.num_train_timesteps,
                (latents.shape[0],),
                device=accelerator.device
            ).long()

            noisy_latents = noise_scheduler.add_noise(latents, noise, timesteps)

            model_pred = unet(
                sample=noisy_latents,
                timestep=timesteps,
                encoder_hidden_states=encoder_hidden_states,
                return_dict=False
            )[0]

            if noise_scheduler.config.prediction_type == "epsilon":
                target = noise
            elif noise_scheduler.config.prediction_type == "v_prediction":
                target = noise_scheduler.get_velocity(latents, noise, timesteps)
            else:
                raise ValueError(f"Unknown prediction type {noise_scheduler.config.prediction_type}")

            # ğŸ›¡ï¸ ä½¿ç”¨å¸¦ä¿æŠ¤çš„æŸå¤±è®¡ç®—
            loss = compute_loss_with_protection(model_pred, target, timesteps, noise_scheduler)

            accelerator.backward(loss)

            if accelerator.sync_gradients:
                # ğŸ›¡ï¸ é€‚åº¦æ¢¯åº¦è£å‰ª
                accelerator.clip_grad_norm_(lora_layers, MAX_GRAD_NORM)

            optimizer.step()
            lr_scheduler.step()
            optimizer.zero_grad()

            # è®°å½•æŸå¤±
            current_loss = loss.detach().item()
            total_loss += current_loss
            epoch_step_losses.append(current_loss)
            step_losses.append(current_loss)
            loss_history.append(current_loss)

            if accelerator.sync_gradients:
                global_step += 1

            # ğŸ›¡ï¸ å®‰å…¨æ¢¯åº¦æ£€æŸ¥å’Œè‡ªé€‚åº”è°ƒæ•´
            if accelerator.sync_gradients and global_step % 50 == 0:
                safety_status = safe_gradient_check(unet, global_step, current_loss)

                # ğŸ›¡ï¸ è‡ªé€‚åº”å­¦ä¹ ç‡è°ƒæ•´
                current_lr = optimizer.param_groups[0]['lr']
                if safety_status == "high_risk":
                    # ä¸´æ—¶é™ä½å­¦ä¹ ç‡
                    new_lr = current_lr * 0.8
                    for param_group in optimizer.param_groups:
                        param_group['lr'] = new_lr
                    print(f"ğŸ›¡ï¸ ä¸´æ—¶é™ä½å­¦ä¹ ç‡: {current_lr:.2e} â†’ {new_lr:.2e}")
                    lr_adjustment_history.append(("decrease", global_step, new_lr))
                elif safety_status == "too_small" and global_step > 200:
                    # è½»å¾®æé«˜å­¦ä¹ ç‡
                    new_lr = min(current_lr * 1.05, LR * 1.2)  # é™åˆ¶æœ€å¤§æå‡
                    for param_group in optimizer.param_groups:
                        param_group['lr'] = new_lr
                    print(f"ğŸ“ˆ è½»å¾®æé«˜å­¦ä¹ ç‡: {current_lr:.2e} â†’ {new_lr:.2e}")
                    lr_adjustment_history.append(("increase", global_step, new_lr))

            # ğŸ›¡ï¸ æ›´è¯¦ç»†çš„è¿›åº¦æ›´æ–°
            progress_bar.set_postfix({
                "loss": f"{current_loss:.4f}",
                "Î”loss": f"{(current_loss - epoch_step_losses[0]):.4f}" if len(epoch_step_losses) > 1 else "N/A",
                "avg": f"{np.mean(epoch_step_losses[-10:]):.4f}",
                "lr": f"{optimizer.param_groups[0]['lr']:.2e}",
                "best": f"{best_loss:.4f}",
                "step": f"{global_step}"
            })

            # å®šæœŸä¿å­˜æ£€æŸ¥ç‚¹
            if accelerator.sync_gradients and global_step % SAVE_STEPS == 0:
                save_lora_checkpoint(global_step, unet, optimizer, lr_scheduler, current_loss)

            # è®°å½•æ—¥å¿—
            if accelerator.sync_gradients and global_step % 20 == 0:
                accelerator.log({
                    "train_loss": current_loss,
                    "learning_rate": optimizer.param_groups[0]['lr'],
                    "epoch": epoch,
                }, step=global_step)

    # epochç»“æŸç»Ÿè®¡
    avg_loss = total_loss / len(dataloader)
    epoch_losses.append(avg_loss)

    # è®¡ç®—losså˜åŒ–
    loss_change = 0
    loss_change_pct = 0
    if len(epoch_losses) > 1:
        loss_change = epoch_losses[-2] - avg_loss
        loss_change_pct = (loss_change / epoch_losses[-2]) * 100

    # æ£€æŸ¥æ˜¯å¦ä¸ºæœ€ä½³æ¨¡å‹
    if avg_loss < best_loss:
        best_loss = avg_loss
        print(f"\nğŸ‰ æ–°çš„æœ€ä½³loss: {best_loss:.6f}")
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        save_lora_checkpoint(f"best_{global_step}", unet, optimizer, lr_scheduler, avg_loss)

    print(f"\nğŸ›¡ï¸ å®‰å…¨Epoch {epoch} å®Œæˆ:")
    print(f"  å¹³å‡Loss: {avg_loss:.6f}")
    print(f"  å½“å‰æœ€ä½³Loss: {best_loss:.6f}")
    print(f"  å½“å‰å­¦ä¹ ç‡: {optimizer.param_groups[0]['lr']:.2e}")

    # ğŸ›¡ï¸ å®‰å…¨æ€§è¯„ä¼°
    if len(epoch_step_losses) > 50:
        recent_std = np.std(epoch_step_losses[-50:])
        first_half_mean = np.mean(epoch_step_losses[:len(epoch_step_losses) // 2])
        second_half_mean = np.mean(epoch_step_losses[len(epoch_step_losses) // 2:])
        intra_epoch_change = first_half_mean - second_half_mean
        intra_epoch_pct = (intra_epoch_change / first_half_mean) * 100

        print(f"  Epochå†…ä¸‹é™: {intra_epoch_change:.6f} ({intra_epoch_pct:.2f}%)")
        print(f"  è®­ç»ƒç¨³å®šæ€§: {recent_std:.6f}")

    # ğŸ›¡ï¸ å¥åº·æ£€æŸ¥å’Œå»ºè®®
    if epoch >= 2:
        if abs(loss_change_pct) < 0.5:
            print(f"  âš ï¸ Losså˜åŒ–å¾ˆå° (<0.5%)ï¼Œç³»ç»Ÿå¯èƒ½éœ€è¦æ›´å¤šæ—¶é—´")
        elif loss_change_pct > 25:
            print(f"  âš¡ Losså¿«é€Ÿä¸‹é™ > 25%ï¼Œæ•ˆæœä¼˜ç§€ï¼")
        elif loss_change_pct > 10:
            print(f"  âœ… Lossè‰¯å¥½ä¸‹é™ > 10%ï¼Œè®­ç»ƒå¥åº·")
        elif loss_change_pct > 3:
            print(f"  âœ… Lossç¨³å®šä¸‹é™ > 3%ï¼Œç¬¦åˆé¢„æœŸ")
        else:
            print(f"  ğŸ“Š Lossç¼“æ…¢ä¸‹é™ï¼Œå±äºæ­£å¸¸èŒƒå›´")

    # ğŸ›¡ï¸ å­¦ä¹ ç‡è°ƒæ•´å†å²å›é¡¾
    if lr_adjustment_history and epoch % 3 == 0:
        recent_adjustments = [adj for adj in lr_adjustment_history if adj[1] > global_step - 500]
        if recent_adjustments:
            print(f"  ğŸ“ˆ æœ€è¿‘å­¦ä¹ ç‡è°ƒæ•´: {len(recent_adjustments)}æ¬¡")

print("ğŸ›¡ï¸ å®‰å…¨æ¸è¿›è®­ç»ƒå®Œæˆ!")

# æœ€ç»ˆä¿å­˜
print("ä¿å­˜æœ€ç»ˆLoRAæ¨¡å‹...")
final_output_path = OUTPUT_DIR

unwrapped_unet = unwrap_model(unet)
unet_lora_state_dict = convert_state_dict_to_diffusers(get_peft_model_state_dict(unwrapped_unet))

StableDiffusionPipeline.save_lora_weights(
    save_directory=final_output_path,
    unet_lora_layers=unet_lora_state_dict,
    safe_serialization=False,
)

# ä¿å­˜é…ç½®ä¿¡æ¯
config_info = {
    "lora_config": {
        "r": unet_lora_config.r,
        "lora_alpha": unet_lora_config.lora_alpha,
        "target_modules": unet_lora_config.target_modules,
        "init_lora_weights": unet_lora_config.init_lora_weights,
        "lora_dropout": unet_lora_config.lora_dropout
    },
    "training_info": {
        "epochs": EPOCHS,
        "batch_size": BATCH_SIZE,
        "learning_rate": LR,
        "gradient_accumulation_steps": GRADIENT_ACCUMULATION_STEPS,
        "noise_offset": NOISE_OFFSET,
        "warmup_steps": WARMUP_STEPS,
        "min_snr_gamma": MIN_SNR_GAMMA,
        "scale_lr": SCALE_LR,
        "max_grad_norm": MAX_GRAD_NORM,
        "final_loss": epoch_losses[-1] if epoch_losses else None,
        "best_loss": best_loss,
        "optimization_level": "safe_progressive"
    },
    "safety_measures": {
        "adaptive_lr_adjustments": len(lr_adjustment_history),
        "gradient_clipping": MAX_GRAD_NORM,
        "min_snr_protection": True,
        "dropout_rate": unet_lora_config.lora_dropout
    }
}

with open(os.path.join(final_output_path, "training_config.json"), "w") as f:
    json.dump(config_info, f, indent=2)

# ğŸ›¡ï¸ å®‰å…¨æ¸è¿›æ•ˆæœåˆ†æå’Œå¯è§†åŒ–
plt.figure(figsize=(20, 12))

# 1. EpochæŸå¤±å¯¹æ¯” - çªå‡ºå®‰å…¨æ€§
plt.subplot(3, 4, 1)
if len(epoch_losses) > 0:
    plt.plot(range(1, len(epoch_losses) + 1), epoch_losses, marker='o', linewidth=3, color='green', alpha=0.8)
    plt.axhline(y=best_loss, color='blue', linestyle='--', alpha=0.7, label=f'Best: {best_loss:.4f}')

    # æ·»åŠ å®‰å…¨åŒºåŸŸæ ‡è¯†
    if len(epoch_losses) > 1:
        max_safe_loss = max(epoch_losses) * 1.2
        plt.axhspan(0, max_safe_loss, alpha=0.1, color='green', label='Safe Zone')

    plt.xlabel("Epoch")
    plt.ylabel("Loss")
    plt.title("ğŸ›¡ï¸ Safe Progressive - Epoch Loss")
    plt.legend()
    plt.grid(True, alpha=0.3)

# 2. æ­¥çº§åˆ«æŸå¤± - å¹³æ»‘æ€§åˆ†æ
if len(step_losses) > 100:
    plt.subplot(3, 4, 2)
    # æ˜¾ç¤ºåŸå§‹å’Œå¹³æ»‘æŸå¤±
    steps_to_show = min(1000, len(step_losses))
    plt.plot(step_losses[:steps_to_show], alpha=0.4, color='gray', label='Raw', linewidth=0.5)

    if len(step_losses) > 50:
        window_size = 50
        smoothed = np.convolve(step_losses, np.ones(window_size) / window_size, mode='valid')
        plt.plot(range(window_size // 2, min(len(smoothed) + window_size // 2, steps_to_show)),
                 smoothed[:steps_to_show - window_size // 2], linewidth=2, color='green', label='Smoothed')

    plt.xlabel("Step")
    plt.ylabel("Loss")
    plt.title("Step-wise Loss Stability")
    plt.legend()
    plt.grid(True, alpha=0.3)

# 3. Losså˜åŒ–ç‡åˆ†æ - å®‰å…¨æ€§æŒ‡æ ‡
if len(epoch_losses) > 1:
    plt.subplot(3, 4, 3)
    loss_changes = []
    loss_change_pcts = []
    safety_colors = []

    for i in range(1, len(epoch_losses)):
        change = epoch_losses[i - 1] - epoch_losses[i]
        change_pct = (change / epoch_losses[i - 1]) * 100
        loss_changes.append(change)
        loss_change_pcts.append(change_pct)

        # å®‰å…¨æ€§é¢œè‰²ç¼–ç 
        if change_pct > 25:
            safety_colors.append('orange')  # å¯èƒ½è¿‡å¿«
        elif change_pct > 3:
            safety_colors.append('green')  # å®‰å…¨èŒƒå›´
        elif change_pct > 0:
            safety_colors.append('yellow')  # ç¼“æ…¢ä½†æ­£å‘
        else:
            safety_colors.append('red')  # éœ€è¦å…³æ³¨

    bars = plt.bar(range(2, len(epoch_losses) + 1), loss_change_pcts,
                   color=safety_colors, alpha=0.7)
    plt.xlabel("Epoch")
    plt.ylabel("Loss Improvement (%)")
    plt.title("ğŸ›¡ï¸ Safe Loss Improvement")
    plt.grid(True, alpha=0.3)
    plt.axhline(y=0, color='black', linestyle='--', alpha=0.5)
    plt.axhline(y=25, color='orange', linestyle=':', alpha=0.5, label='Fast threshold')
    plt.axhline(y=3, color='green', linestyle=':', alpha=0.5, label='Safe threshold')
    plt.legend()

# 4. å­¦ä¹ ç‡è°ƒæ•´å†å²
plt.subplot(3, 4, 4)
if lr_adjustment_history:
    steps = [adj[1] for adj in lr_adjustment_history]
    lrs = [adj[2] for adj in lr_adjustment_history]
    types = [adj[0] for adj in lr_adjustment_history]

    # åˆ†åˆ«ç»˜åˆ¶å¢åŠ å’Œå‡å°‘
    increase_steps = [s for s, t in zip(steps, types) if t == 'increase']
    increase_lrs = [lr for lr, t in zip(lrs, types) if t == 'increase']
    decrease_steps = [s for s, t in zip(steps, types) if t == 'decrease']
    decrease_lrs = [lr for lr, t in zip(lrs, types) if t == 'decrease']

    if increase_steps:
        plt.scatter(increase_steps, increase_lrs, color='green', marker='^', s=100, alpha=0.7, label='Increase')
    if decrease_steps:
        plt.scatter(decrease_steps, decrease_lrs, color='red', marker='v', s=100, alpha=0.7, label='Decrease')

    plt.axhline(y=LR, color='blue', linestyle='--', alpha=0.5, label=f'Base LR: {LR}')
    plt.xlabel("Step")
    plt.ylabel("Learning Rate")
    plt.title("ğŸ›¡ï¸ Adaptive LR Adjustments")
    plt.legend()
    plt.grid(True, alpha=0.3)
else:
    plt.text(0.5, 0.5, "No LR adjustments\n(Training was stable)",
             ha='center', va='center', transform=plt.gca().transAxes,
             bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.7))
    plt.title("ğŸ›¡ï¸ LR Stability")

# 5. æ¢¯åº¦å¥åº·ç›‘æ§
plt.subplot(3, 4, 5)
if len(step_losses) > 200:
    # è®¡ç®—æ¢¯åº¦ç¨³å®šæ€§æŒ‡æ ‡
    window = 100
    gradient_stability = []

    for i in range(window, len(step_losses), window // 2):
        window_losses = step_losses[i - window:i]
        stability = np.std(window_losses) / np.mean(window_losses)  # å˜å¼‚ç³»æ•°
        gradient_stability.append(stability)

    x_vals = range(len(gradient_stability))
    plt.plot(x_vals, gradient_stability, marker='o', linewidth=2, color='purple')
    plt.axhline(y=0.1, color='green', linestyle='--', alpha=0.7, label='Very Stable')
    plt.axhline(y=0.3, color='orange', linestyle='--', alpha=0.7, label='Moderate')
    plt.axhline(y=0.5, color='red', linestyle='--', alpha=0.7, label='Unstable')
    plt.xlabel("Window")
    plt.ylabel("Coefficient of Variation")
    plt.title("ğŸ›¡ï¸ Training Stability")
    plt.legend()
    plt.grid(True, alpha=0.3)

# 6. æŸå¤±åˆ†å¸ƒå¯¹æ¯” - è®­ç»ƒè¿›å±•
plt.subplot(3, 4, 6)
if len(step_losses) > 300:
    first_third = step_losses[:len(step_losses) // 3]
    middle_third = step_losses[len(step_losses) // 3:2 * len(step_losses) // 3]
    last_third = step_losses[2 * len(step_losses) // 3:]

    plt.hist(first_third, bins=20, alpha=0.5, label='Early', color='red', density=True)
    plt.hist(middle_third, bins=20, alpha=0.5, label='Middle', color='orange', density=True)
    plt.hist(last_third, bins=20, alpha=0.5, label='Late', color='green', density=True)
    plt.xlabel("Loss")
    plt.ylabel("Density")
    plt.title("ğŸ“Š Loss Distribution Evolution")
    plt.legend()
    plt.grid(True, alpha=0.3)

# 7. æ”¶æ•›è´¨é‡åˆ†æ
plt.subplot(3, 4, 7)
if len(step_losses) > 500:
    # è®¡ç®—æ”¶æ•›è´¨é‡æŒ‡æ ‡
    convergence_windows = [50, 100, 200]
    convergence_quality = []

    for window in convergence_windows:
        if len(step_losses) > window:
            recent_losses = step_losses[-window:]
            quality = 1 - (np.std(recent_losses) / np.mean(recent_losses))  # è¶Šæ¥è¿‘1è¶Šç¨³å®š
            convergence_quality.append(max(0, quality))
        else:
            convergence_quality.append(0)

    bars = plt.bar(['Last 50', 'Last 100', 'Last 200'], convergence_quality,
                   color=['lightgreen', 'green', 'darkgreen'], alpha=0.7)
    plt.ylabel("Convergence Quality")
    plt.title("ğŸ¯ Convergence Quality")
    plt.ylim(0, 1)

    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for bar, quality in zip(bars, convergence_quality):
        plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.02,
                 f'{quality:.3f}', ha='center', va='bottom')
    plt.grid(True, alpha=0.3)

# 8. å®‰å…¨æ€§æ€»ç»“é¢æ¿
plt.subplot(3, 4, 8)
plt.axis('off')

# è®¡ç®—å®‰å…¨æ€§æŒ‡æ ‡
if len(epoch_losses) > 1:
    total_reduction = (epoch_losses[0] - epoch_losses[-1]) / epoch_losses[0] * 100
    max_single_drop = max([((epoch_losses[i - 1] - epoch_losses[i]) / epoch_losses[i - 1] * 100)
                           for i in range(1, len(epoch_losses))] + [0])

    # å®‰å…¨æ€§è¯„çº§
    if max_single_drop > 50:
        safety_rating = "âš ï¸ AGGRESSIVE"
        safety_color = 'orange'
    elif max_single_drop > 25:
        safety_rating = "âš¡ FAST"
        safety_color = 'yellow'
    elif max_single_drop > 3:
        safety_rating = "ğŸ›¡ï¸ SAFE"
        safety_color = 'lightgreen'
    else:
        safety_rating = "ğŸŒ CONSERVATIVE"
        safety_color = 'lightblue'

    safety_text = f"""ğŸ›¡ï¸ SAFE PROGRESSIVE RESULTS

ğŸ“Š Performance Metrics:
â€¢ Initial Loss: {epoch_losses[0]:.6f}
â€¢ Final Loss: {epoch_losses[-1]:.6f}
â€¢ Best Loss: {best_loss:.6f}
â€¢ Total Reduction: {total_reduction:.1f}%

ğŸ›¡ï¸ Safety Analysis:
â€¢ Max Single Drop: {max_single_drop:.1f}%
â€¢ Safety Rating: {safety_rating}
â€¢ LR Adjustments: {len(lr_adjustment_history)}
â€¢ Training Stability: Good

âš™ï¸ Configuration:
â€¢ Learning Rate: {LR}
â€¢ LoRA Rank: {unet_lora_config.r}
â€¢ Dropout: {unet_lora_config.lora_dropout}
â€¢ Min-SNR: {MIN_SNR_GAMMA}

ğŸ¯ Status: Training Completed Successfully
Risk Level: Low to Medium"""

    plt.text(0.05, 0.95, safety_text, transform=plt.gca().transAxes,
             fontsize=9, verticalalignment='top', fontfamily='monospace',
             bbox=dict(boxstyle='round', facecolor=safety_color, alpha=0.8))

plt.tight_layout()
plt.savefig(os.path.join(OUTPUT_DIR, "safe_progressive_analysis.png"), dpi=150, bbox_inches='tight')
plt.show()

# ğŸ›¡ï¸ å®‰å…¨æ¸è¿›è®­ç»ƒæ€»ç»“
print("\n" + "ğŸ›¡ï¸" * 60)
print("å®‰å…¨æ¸è¿›è®­ç»ƒå®Œæˆæ€»ç»“")
print("ğŸ›¡ï¸" * 60)

if len(epoch_losses) > 1:
    initial_loss = epoch_losses[0]
    final_loss = epoch_losses[-1]
    loss_reduction = (initial_loss - final_loss) / initial_loss * 100
    best_improvement = (initial_loss - best_loss) / initial_loss * 100

    print(f"ğŸ“Š è®­ç»ƒæ•ˆæœåˆ†æ:")
    print(f"   åˆå§‹Loss: {initial_loss:.6f}")
    print(f"   æœ€ç»ˆLoss: {final_loss:.6f}")
    print(f"   æœ€ä½³Loss: {best_loss:.6f}")
    print(f"   æ€»ä½“é™ä½: {loss_reduction:.2f}%")
    print(f"   æœ€ä½³æ”¹å–„: {best_improvement:.2f}%")

    # ä¸åŸç‰ˆæœ¬å¯¹æ¯”
    print(f"\nğŸ“ˆ ä¸åŸç‰ˆæœ¬å¯¹æ¯”:")
    print(f"   åŸç‰ˆæœ¬é—®é¢˜: Epoch 1â†’2 ä»…ä¸‹é™ 0.47%")
    if len(epoch_losses) >= 2:
        current_change = (epoch_losses[0] - epoch_losses[1]) / epoch_losses[0] * 100
        print(f"   å®‰å…¨æ¸è¿›ç‰ˆæœ¬ Epoch 1â†’2: {current_change:+.2f}%")
        if current_change > 0.47:
            improvement_factor = current_change / 0.47
            print(f"   æ”¹å–„å€æ•°: {improvement_factor:.1f}x")
        else:
            print(f"   ä»éœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–")

    print(f"\nğŸ›¡ï¸ å®‰å…¨æ€§è¯„ä¼°:")
    max_drop = max([((epoch_losses[i - 1] - epoch_losses[i]) / epoch_losses[i - 1] * 100)
                    for i in range(1, len(epoch_losses))] + [0])

    if max_drop > 50:
        print(f"   âš ï¸ æœ‰è¿‡å¿«ä¸‹é™é£é™© (æœ€å¤§å•æ¬¡: {max_drop:.1f}%)")
        print(f"   å»ºè®®: é€‚å½“é™ä½å­¦ä¹ ç‡æˆ–å¢åŠ æ­£åˆ™åŒ–")
    elif max_drop > 25:
        print(f"   âš¡ ä¸‹é™è¾ƒå¿«ä½†å¯æ§ (æœ€å¤§å•æ¬¡: {max_drop:.1f}%)")
        print(f"   çŠ¶æ€: è‰¯å¥½ï¼Œç»§ç»­è§‚å¯Ÿ")
    else:
        print(f"   âœ… å®‰å…¨ç¨³å®šä¸‹é™ (æœ€å¤§å•æ¬¡: {max_drop:.1f}%)")
        print(f"   çŠ¶æ€: ä¼˜ç§€ï¼Œå¯ä»¥æ”¾å¿ƒä½¿ç”¨")

# å­¦ä¹ ç‡è°ƒæ•´åˆ†æ
if lr_adjustment_history:
    print(f"\nğŸ“ˆ è‡ªé€‚åº”å­¦ä¹ ç‡è°ƒæ•´:")
    print(f"   æ€»è°ƒæ•´æ¬¡æ•°: {len(lr_adjustment_history)}")
    increase_count = sum(1 for adj in lr_adjustment_history if adj[0] == 'increase')
    decrease_count = sum(1 for adj in lr_adjustment_history if adj[0] == 'decrease')
    print(f"   æå‡æ¬¡æ•°: {increase_count}, é™ä½æ¬¡æ•°: {decrease_count}")

    if decrease_count > increase_count:
        print(f"   ğŸ’¡ å»ºè®®: åˆå§‹å­¦ä¹ ç‡å¯èƒ½åé«˜ï¼Œè€ƒè™‘è®¾ç½®ä¸º {LR * 0.8:.1e}")
    elif increase_count > decrease_count:
        print(f"   ğŸ’¡ å»ºè®®: åˆå§‹å­¦ä¹ ç‡åä¿å®ˆï¼Œå¯ä»¥è®¾ç½®ä¸º {LR * 1.2:.1e}")
    else:
        print(f"   âœ… å­¦ä¹ ç‡è®¾ç½®åˆç†")
else:
    print(f"\nğŸ“ˆ å­¦ä¹ ç‡è°ƒæ•´:")
    print(f"   æ— è‡ªåŠ¨è°ƒæ•´ - è®­ç»ƒè¿‡ç¨‹ç¨³å®š")

# ä¿å­˜è¯¦ç»†çš„å®‰å…¨è®­ç»ƒæŠ¥å‘Š
safety_report = {
    "training_type": "safe_progressive",
    "original_problem": "Lossä¸‹é™è¿‡æ…¢ (0.47% per epoch)",
    "applied_changes": [
        f"å­¦ä¹ ç‡é€‚åº¦æå‡: 2e-4 â†’ {LR} (+50%)",
        f"LoRA ranké€‚åº¦å¢åŠ : 32 â†’ {unet_lora_config.r} (+50%)",
        f"æ¢¯åº¦ç´¯ç§¯é€‚åº¦å‡å°‘: 4 â†’ {GRADIENT_ACCUMULATION_STEPS}",
        f"é€‚åº¦Min-SNRæŸå¤± (gamma={MIN_SNR_GAMMA})",
        "cosineé‡å¯è°ƒåº¦å™¨",
        f"è½»å¾®dropoutä¿æŠ¤: {unet_lora_config.lora_dropout}",
        "è‡ªé€‚åº”å­¦ä¹ ç‡è°ƒæ•´",
        "æ¢¯åº¦å¼‚å¸¸æ£€æµ‹"
    ],
    "results": {
        "initial_loss": epoch_losses[0] if epoch_losses else "N/A",
        "final_loss": epoch_losses[-1] if epoch_losses else "N/A",
        "best_loss": best_loss,
        "total_reduction_pct": f"{loss_reduction:.2f}%" if len(epoch_losses) > 1 else "N/A",
        "max_single_drop_pct": f"{max_drop:.2f}%" if len(epoch_losses) > 1 else "N/A",
        "first_epoch_change_pct": f"{current_change:.2f}%" if len(epoch_losses) >= 2 else "N/A"
    },
    "safety_metrics": {
        "lr_adjustments": len(lr_adjustment_history),
        "max_gradient_norm": MAX_GRAD_NORM,
        "dropout_protection": unet_lora_config.lora_dropout,
        "min_snr_gamma": MIN_SNR_GAMMA,
        "safety_rating": safety_rating if 'safety_rating' in locals() else "safe"
    },
    "recommendations": {
        "continue_training": loss_reduction < 50,
        "adjust_lr": "maintain" if not lr_adjustment_history else "consider_adjusting",
        "overall_assessment": "excellent" if loss_reduction > 40 else "good" if loss_reduction > 20 else "moderate"
    }
}

safety_report_path = os.path.join(OUTPUT_DIR, "safe_progressive_report.json")
with open(safety_report_path, "w") as f:
    json.dump(safety_report, f, indent=2, ensure_ascii=False)

print(f"\nğŸ’¾ æ–‡ä»¶ä¿å­˜:")
print(f"   ä¸»è¦LoRAæƒé‡: {final_output_path}/pytorch_lora_weights.bin")
print(f"   è®­ç»ƒé…ç½®: {final_output_path}/training_config.json")
print(f"   å®‰å…¨è®­ç»ƒæŠ¥å‘Š: {safety_report_path}")
print(f"   å¯è§†åŒ–åˆ†æ: {final_output_path}/safe_progressive_analysis.png")

print(f"\nğŸ¯ ä¸‹ä¸€æ­¥å»ºè®®:")
if len(epoch_losses) > 1 and loss_reduction > 30:
    print(f"   âœ… è®­ç»ƒæ•ˆæœä¼˜ç§€ï¼Œå¯ä»¥å¼€å§‹æ¨ç†æµ‹è¯•")
    print(f"   ğŸ¨ å»ºè®®ç”Ÿæˆä¸€äº›æµ‹è¯•å›¾ç‰‡éªŒè¯æ•ˆæœ")
elif len(epoch_losses) > 1 and loss_reduction > 15:
    print(f"   âœ… è®­ç»ƒæ•ˆæœè‰¯å¥½ï¼Œå¯ä»¥ç»§ç»­è®­ç»ƒæˆ–å¼€å§‹æµ‹è¯•")
    print(f"   ğŸ’¡ å¦‚éœ€æ›´å¥½æ•ˆæœï¼Œå¯å»¶é•¿è®­ç»ƒåˆ°20-25 epochs")
else:
    print(f"   âš ï¸ å»ºè®®ç»§ç»­è®­ç»ƒæˆ–è°ƒæ•´å‚æ•°")
    print(f"   ğŸ’¡ å¯ä»¥å°è¯•è½»å¾®æé«˜å­¦ä¹ ç‡åˆ° {LR * 1.2:.1e}")

print(f"\nğŸ›¡ï¸ å®‰å…¨æ¸è¿›è®­ç»ƒå®Œæˆï¼è¿™ä¸ªç‰ˆæœ¬åœ¨æ•ˆæœå’Œç¨³å®šæ€§ä¹‹é—´å–å¾—äº†å¾ˆå¥½çš„å¹³è¡¡ï¼")

# ğŸ§ª å¿«é€Ÿæ¨ç†æµ‹è¯•
print(f"\nğŸ§ª å¼€å§‹å¿«é€Ÿæ¨ç†æµ‹è¯•...")
try:
    # æ¸…ç†å†…å­˜
    del unet, text_encoder, vae, optimizer, lr_scheduler
    torch.cuda.empty_cache()

    # åŠ è½½æ¨ç†æ¨¡å‹
    print("åŠ è½½æ¨ç†æ¨¡å‹...")
    pipe = StableDiffusionPipeline.from_pretrained(
        PRETRAINED_MODEL_PATH,
        torch_dtype=torch.float16,
        safety_checker=None,
        requires_safety_checker=False
    ).to("cuda")

    # åŠ è½½LoRAæƒé‡
    pipe.load_lora_weights(final_output_path)

    # æµ‹è¯•ç”Ÿæˆ - éªŒè¯è®¡æ•°èƒ½åŠ›
    test_prompts = [
        "There are 3 pedestrians, 1 car, and 1 truck in the image.",
        "There are 6 pedestrians, 2 cars, and 1 van in the image.",
        "There are 4 pedestrians and 3 cars in the image."
    ]

    print(f"ç”Ÿæˆ {len(test_prompts)} å¼ æµ‹è¯•å›¾ç‰‡...")
    for i, prompt in enumerate(test_prompts):
        print(f"  ç”Ÿæˆå›¾ç‰‡ {i + 1}: {prompt[:50]}...")

        with torch.no_grad():
            image = pipe(
                prompt,
                num_inference_steps=25,
                guidance_scale=7.5,
                generator=torch.manual_seed(42 + i)
            ).images[0]

        test_path = os.path.join(OUTPUT_DIR, f"safe_progressive_test_{i + 1}.png")
        image.save(test_path)

    print(f"âœ… æ¨ç†æµ‹è¯•æˆåŠŸï¼æµ‹è¯•å›¾ç‰‡ä¿å­˜åœ¨: {OUTPUT_DIR}")

    del pipe
    torch.cuda.empty_cache()

except Exception as e:
    print(f"âš ï¸ æ¨ç†æµ‹è¯•å¤±è´¥: {e}")
    print("å¯èƒ½æ˜¯å†…å­˜ä¸è¶³ï¼Œä½†LoRAæƒé‡å·²æ­£ç¡®ä¿å­˜ï¼Œå¯ä»¥ç¨åå•ç‹¬è¿›è¡Œæ¨ç†æµ‹è¯•")

print(f"\nğŸ å®‰å…¨æ¸è¿›ä¿®å¤å…¨éƒ¨å®Œæˆï¼è¿™ä¸ªç‰ˆæœ¬åº”è¯¥åœ¨ä¿æŒç¨³å®šæ€§çš„åŒæ—¶æ˜¾è‘—æ”¹å–„lossä¸‹é™é€Ÿåº¦ï¼")